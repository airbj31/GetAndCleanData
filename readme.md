# Final Program Assignment of Getting and Cleaning DATA course on Coursera.org.
Byungju Kim  
Feb 28, 2016  

# Introduction

This is the last program assignment of Getting and Cleaning data course.

The purpose of the assignment is to evaluate if I can get and clean data.

the end-product of the assignment was deposited into my github repository named as [UCISamsungGalaxySIISummary.txt](https://github.com/airbj31/GetAndCleanData/blob/master/UCISamsungGalaxySIISummary.txt)

the description is written in [codebook.md](https://github.com/airbj31/GetAndCleanData/blob/master/codebook.md)

# Description of submitted data into github

- **[readme.md](https://github.com/airbj31/GetAndCleanData/blob/master/readme.md)** - this file

- **[run_analysis.R](https://github.com/airbj31/GetAndCleanData/blob/master/analysis.R)** : assignment R code used to get and clean UCI samsung galaxy SII wearable device data.

- **[UCISamsungGalaxySIISummary.txt](https://github.com/airbj31/GetAndCleanData/blob/master/UCISamsungGalaxySIISummary.txt)** : summary tidy dataset generated from [run_analysis.R](https://github.com/airbj31/GetAndCleanData/blob/master/analysis.R)

- **[codebook.md](https://github.com/airbj31/GetAndCleanData/blob/master/codebook.md)** - description about [UCISamsungGalaxySIISummary.txt](https://github.com/airbj31/GetAndCleanData/blob/master/UCISamsungGalaxySIISummary.txt)

# Running of the code.

1. download the [run_analysis.R](https://github.com/airbj31/GetAndCleanData/blob/master/analysis.R) into your working directory.

2. source("run_analysis.R") to download andy tidify data.

   two dataset will be generated by the run_analysis.R
   
   - **tidyGalaxy** : first data set.
   - **tidyGalaxySummary** : second, summarized dataset.this is the output of the run_analysis.R
 
   beside of the output, the script generate two function.
   
   - **merge3DF(file1,file2,file3)** : used to merge 3 dataset.
   - **num2act(x)** from the input of digit variable x, it redirect vector value which is human readable activity.
   
# Workflows and detailed code description

## Understanding about the data

  * **features.txt** List of all variables ( 561 x 2 ). this file is used to extract column name.

  * **activity_labels.txt** code and activity label (6 x 2). Since the order of the items are same with line-number, we do not need to use 1st column. we need simple function which redirects the code's real activity (see num2act(x) in run_analysis.R). 

  * **train/X_train.txt** and **test/X_test.txt** Training and Test set data (train/X_train.txt : 7352 x 561; test_X_test.txt : 2947 x 561). 
  
      Each row identifies the subject who performed the activity for each window sample. 
      Its range is from 1 to 30.
      
      there is no common id between train and test set.
      
      training set is x 561
      test set is x ~~~.

  * **train/Y_train.txt** and **test/Y_test.txt** activity label ( train/Y_train.txt :7352 x 1; test/Y_test.txt : 2947 x 1)

## Make strategy to get and clean data.

1. **features.txt** would be used to column name.
2. **train** and **test** data should be separately handled and merged since their observation numbers are different. 
3. use dplyr and tidyr to make tidy data an make summary.

## Step 0. Data download and load library

  In this step we first load required library for data analysis and download data from web.


```r
  ## 0-A. Load Library 

  require(dplyr)
  require(tidyr)

  ## 0-B. Initial variable declaration

    ## declare fileURL for download data
    fileURL<-"https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
  
    ## declare data folder 
    dir<-"data"

    ## downloaded zip file name
    dfile<-"LastPA.zip"
  
  ## 0-C check directory existence
  if(!file.exists(dir)) {
    dir.create(dir)  ## if directory is not exists, make one.  
  }
  
  ## 0-D. download and unzip data
    
    ## make dest file path and name
    dfile2<-paste(dir,dfile,sep="/")
  
    ## download file
    download.file(fileURL,destfile=dfile2)

    ## unzip downloaded file into dir folder.
    unzip(dfile2,exdir=dir)

  ## 0-E. set base data directory as dir variable for further usage. 
    dir<-paste(dir,"UCI HAR Dataset",sep="/")
```

## Step 1. Read Data and merge.them

in this step, We read 3 data frames from test and training directory and merge them into one data frame.


```r
  ## 1. Define function for merging data 
  
  ## alternatively, we can use join() or join_all() function.
  
  Merge3DF <-function(dirPATH,File1,File2,File3,...)
  {
    filePATH<-paste(dirPATH,File1,sep="/")
    df1<-read.table(filePATH,...)
    filePATH<-paste(dirPATH,File2,sep="/")
    df2<-read.table(filePATH,...)
    filePATH<-paste(dirPATH,File3,sep="/")
    df3<-read.table(filePATH,...)
    
    ## Merge 3 data into 1 data.frame
    cbind(df1,df2,df3)
  }

    ## get merged train and test set.
    merged.train<-Merge3DF(dir,"train/subject_train.txt","train/y_train.txt","train/X_train.txt",header=FALSE)
    merged.test <-Merge3DF(dir,"test/subject_test.txt","test/y_test.txt","test/X_test.txt",header=FALSE)
  
    ## Merge train and test set
    merged.df<-rbind(merged.train,merged.test)
    rm(merged.train, merged.test)
```

## Step 2. Extracts only the measurements on the mean and standard deviation for each measurement.


```r
  ## 2-A. read column information.
  filePATH<-paste(dir,"features.txt",sep="/")
  VarColname<-as.vector(read.table(filePATH,header=FALSE)[2]$V2)

  ## 2-B. declare colname of merged.df.  
  colnames(merged.df)<-c("sampleid","activity",VarColname)

  ## 2-C. Extracts only the measurements on the mean and standard deviation for each measurement.
  ExtColName<-grep("-mean\\(\\)|-std\\(\\)",VarColname)
  ExtColName<-VarColname[ExtColName]
  
  ## 2-D. to avoid duplicated related error of dplyr select function
  merged.df <- merged.df[,!duplicated(names(merged.df))]
  merged.df <- select(merged.df, one_of(c("sampleid","activity",ExtColName)))
```

## Step 3. Uses descriptive activity names to name the activities in the data set


```r
  ## 3-A. read activity_label to label activity column.
  
  filePATH<-paste(dir,"activity_labels.txt",sep="/")
  activity <- as.vector(read.table(filePATH,col.names = c("id","activity"))[2]$activity)
  activity <- as.vector(activity$activity)
  
  ## 3-B. make simple function which redirect input's human readable activiy.
  num2act <-function(x)
  {
    tolower(activity[x])  
  }
  
  ## 3-C. use mutate function to change column value.
  new.df<-mutate(merged.df,activity=num2act(merged.df$activity))

  ## 3-D. remove temporary data table. 
  rm(merged.df)
```


## Step 4. Appropriately labels the data set with descriptive variable names.

- I used piping and dplyr and tidyr package to tidify data.
  - gather function is used to melt data set and make new columns named mean and std repectively.
  - select function is used to drop unneccesary variable
  - mutate used to change variable name to be more descriptive and readable.


```r
  tidyGalaxy  <- new.df  %>% gather(measurement, mean ,contains("mean()")) %>% 
                      gather(measurement2, std ,contains("std()"))  %>% 
                      select(-measurement2) %>%
                      mutate(measurement=sub("-mean\\(\\)-*","",measurement))
```

## Step 5. make summary data set.

- From the data set in step 4, creates a second, independent tidy data set with the average of each variable for each activity and each subject.


```r
  tidyGalaxySummary <- tidyGalaxy %>% group_by(sampleid,measurement,activity) %>% summarize(mean=mean(mean),std=mean(std))
  print(tidyGalaxySummary) 
  
##   used to save the file 
#  write.table(tidyGalaxySummary,file = "./data/UCISamsungGalaxySIISummary.txt",row.names = FALSE)
#  write.table(tst,file = "./data/UCISamsungGalaxySII.txt")
```
